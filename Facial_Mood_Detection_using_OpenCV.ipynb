{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf5KrEb6vrkR"
      },
      "source": [
        "# Facial Mood Detection using openCV\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y opencv-python opencv-contrib-python\n",
        "!pip install opencv-contrib-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctnkR0wenVJw",
        "outputId": "c8a1d46e-c029-421a-ebd0-6060d83a1432"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping opencv-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: opencv-contrib-python 4.12.0.88\n",
            "Uninstalling opencv-contrib-python-4.12.0.88:\n",
            "  Successfully uninstalled opencv-contrib-python-4.12.0.88\n",
            "Collecting opencv-contrib-python\n",
            "  Using cached opencv_contrib_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-contrib-python) (2.0.2)\n",
            "Using cached opencv_contrib_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (73.2 MB)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "Successfully installed opencv-contrib-python-4.12.0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HndJDJ5AlD6",
        "outputId": "a845c93a-da55-429d-fe6d-0ea49ba01ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenCV version: 4.12.0\n"
          ]
        }
      ],
      "source": [
        "# Core libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"OpenCV version:\", cv2.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XZtIxfXMA3K5"
      },
      "outputs": [],
      "source": [
        "emotion_map = {\n",
        "    0: \"anger\",\n",
        "    1: \"contempt\",\n",
        "    2: \"disgust\",\n",
        "    3: \"fear\",\n",
        "    4: \"happy\",\n",
        "    5: \"sadness\",\n",
        "    6: \"surprise\"\n",
        "}\n",
        "\n",
        "emotion_map_inv = {v: k for k, v in emotion_map.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1gYR04spBpDr"
      },
      "outputs": [],
      "source": [
        "#Load haarcascade for face detection\n",
        "face_cascade = cv2.CascadeClassifier(\n",
        "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
        ")\n",
        "\n",
        "if face_cascade.empty():\n",
        "    raise IOError(\"Haar Cascade not loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XWC4_4jZIu2x"
      },
      "outputs": [],
      "source": [
        "#Face detection and preprocessing\n",
        "def extract_face(img_path, target_size=(200, 200)):\n",
        "    img = cv2.imread(str(img_path))\n",
        "\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.equalizeHist(gray)\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(\n",
        "        gray,\n",
        "        scaleFactor=1.3,\n",
        "        minNeighbors=5\n",
        "    )\n",
        "\n",
        "    if len(faces) == 0:\n",
        "        return None\n",
        "\n",
        "    # Take largest detected face\n",
        "    x, y, w, h = sorted(\n",
        "        faces, key=lambda f: f[2]*f[3], reverse=True\n",
        "    )[0]\n",
        "\n",
        "    face_roi = gray[y:y+h, x:x+w]\n",
        "    face_resized = cv2.resize(face_roi, target_size)\n",
        "\n",
        "    return face_resized\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"archive (6).zip\" -d /content/ck_plus_dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O5CfI0Nl2CZ",
        "outputId": "b86bd2fa-a84b-4be0-a58b-0026a54778f2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  archive (6).zip\n",
            "replace /content/ck_plus_dataset/CK+48/anger/S010_004_00000017.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r9vN8_MI8qY",
        "outputId": "eabf7e02-16a4-460e-c55e-b3a905d75e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples collected: 2\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "data_dir = Path(\"/content/ck_plus_dataset/CK+48\")\n",
        "assert data_dir.exists(), \"Dataset path not found\"\n",
        "\n",
        "faces = []\n",
        "labels = []\n",
        "\n",
        "for emotion_folder in sorted(data_dir.iterdir()):\n",
        "    if not emotion_folder.is_dir():\n",
        "        continue\n",
        "\n",
        "    emotion_label = emotion_map_inv.get(emotion_folder.name)\n",
        "    if emotion_label is None:\n",
        "        continue\n",
        "\n",
        "    for img_path in emotion_folder.glob(\"*.png\"):\n",
        "        face = extract_face(img_path)\n",
        "        if face is not None:\n",
        "            faces.append(face)\n",
        "            labels.append(emotion_label)\n",
        "\n",
        "print(\"Total samples collected:\", len(faces))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "faces = np.array(faces, dtype=\"uint8\")\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(type(faces), type(labels))\n",
        "print(faces.shape, labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jAYBzc7myMV",
        "outputId": "03b853cf-bd2a-48cf-e387-a4a71877afb8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "(2, 200, 200) (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwQCIeJ8JaaA",
        "outputId": "c5fa0797-e32c-4f6f-f79f-b5cd3cbc0f89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 1\n",
            "Test samples: 1\n"
          ]
        }
      ],
      "source": [
        "indices = np.arange(len(faces))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "split = int(0.8 * len(indices))\n",
        "\n",
        "train_idx = indices[:split]\n",
        "test_idx  = indices[split:]\n",
        "\n",
        "X_train, y_train = faces[train_idx], labels[train_idx]\n",
        "X_test,  y_test  = faces[test_idx],  labels[test_idx]\n",
        "\n",
        "print(\"Train samples:\", len(X_train))\n",
        "print(\"Test samples:\", len(X_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhLutrmxLKIt",
        "outputId": "f7678868-a20b-4e24-bf9e-c49fdfa580d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-contrib-python) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-contrib-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "print(\"OpenCV version:\", cv2.__version__)\n",
        "print(\"Has face module:\", hasattr(cv2, \"face\"))\n",
        "\n",
        "if hasattr(cv2, \"face\"):\n",
        "    print(\"LBPH available:\", hasattr(cv2.face, \"LBPHFaceRecognizer_create\"))\n",
        "    print(dir(cv2.face))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI3R4Pmrn_Qh",
        "outputId": "6618cb60-8c48-4209-ddc6-0c5732647698"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenCV version: 4.12.0\n",
            "Has face module: True\n",
            "LBPH available: True\n",
            "['BIF', 'BIF_create', 'BasicFaceRecognizer', 'EigenFaceRecognizer', 'EigenFaceRecognizer_create', 'FaceRecognizer', 'Facemark', 'FacemarkAAM', 'FacemarkKazemi', 'FacemarkLBF', 'FacemarkTrain', 'FisherFaceRecognizer', 'FisherFaceRecognizer_create', 'LBPHFaceRecognizer', 'LBPHFaceRecognizer_create', 'MACE', 'MACE_create', 'MACE_load', 'PredictCollector', 'StandardCollector', 'StandardCollector_create', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_native', 'createFacemarkAAM', 'createFacemarkKazemi', 'createFacemarkLBF', 'drawFacemarks', 'getFacesHAAR', 'loadDatasetList', 'loadFacePoints', 'loadTrainingData']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = cv2.face.LBPHFaceRecognizer_create(\n",
        "    radius=1,\n",
        "    neighbors=8,\n",
        "    grid_x=8,\n",
        "    grid_y=8\n",
        ")\n",
        "\n",
        "model.train(X_train, y_train)\n",
        "print(\"Model training completed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwm76TbdoIMI",
        "outputId": "dfc5e437-c75f-40b4-b0b6-66a262c2ee98"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ar9muIWxO9kh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}